{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of transactions = 284807\n",
      "The total number of fraudulent transactions = 492\n",
      "The number of $0 transactions = 1825\n",
      "The number of $0 transactions which are fraudulent = 27\n",
      "The fraction of all transactions that are fraudulent = 0.173%\n",
      "The fraction of all 0$ transactions that are fraudulent = 1.479%\n",
      "\n",
      "A much higher % of 0$ transactions are fraudulent, compared with the general set. This could bepotentially interesting. However, given the very small number of fraudulent transactions, making inferencesis questionable.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# Attempts to find any improper values:\n",
    "for c in df.columns:\n",
    "    \n",
    "    if df[c].loc[df[c].isnull()].count()>0:\n",
    "        print \"The number of null values in %s = %s\" %(c,df[c].loc[df[c].isnull()].count())\n",
    "        \n",
    "N_transactions = df['V1'].count()\n",
    "N_fraud = df['V1'].loc[df['Class']==1].count()\n",
    "N_zero_transactions = df['Amount'].loc[df['Amount']==0.].count()\n",
    "N_zero_fraud_transactions = df['Amount'].loc[(df['Amount']==0.) & (df['Class']==1)].count()\n",
    "\n",
    "print \"The total number of transactions = %s\" % N_transactions\n",
    "print \"The total number of fraudulent transactions = %s\" % N_fraud\n",
    "print \"The number of $0 transactions = %s\" % N_zero_transactions\n",
    "print \"The number of $0 transactions which are fraudulent = %s\" % N_zero_fraud_transactions\n",
    "\n",
    "print \"The fraction of all transactions that are fraudulent = %.3f%%\" % (100*N_fraud/N_transactions)\n",
    "print \"The fraction of all 0$ transactions that are fraudulent = %.3f%%\" % (100*N_zero_fraud_transactions/N_zero_transactions)\n",
    "\n",
    "print\n",
    "print \"A much higher % of 0$ transactions are fraudulent, compared with the general set. This could be\\\n",
    "potentially interesting. However, given the very small number of fraudulent transactions, making inferences\\\n",
    "is questionable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_no_class = list(df.columns)\n",
    "columns_no_class.remove('Class')\n",
    "\n",
    "df_clean = (df[columns_no_class]-df[columns_no_class].mean())/df[columns_no_class].std()\n",
    "df_clean = pd.concat((df_clean,df['Class']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the dataframe into train and test sets\n",
    "# Do so in a manner which preserves the proportion of classes (so as not to bias the set)\n",
    "# First, split the class=0 indices\n",
    "C_0_train_index, C_0_test_index = train_test_split(df_clean.loc[df['Class']==0].index.values)\n",
    "# First, split the class=1 indices\n",
    "C_1_train_index, C_1_test_index = train_test_split(df_clean.loc[df['Class']==1].index.values)\n",
    "# Copy the data frames into a train and test version, based on the obtained indices\n",
    "df_train = df_clean.loc[np.concatenate((C_0_train_index,C_1_train_index))]\n",
    "df_test = df_clean.loc[np.concatenate((C_0_test_index,C_1_test_index))]\n",
    "\n",
    "df_train_X = df_train[columns_no_class]\n",
    "df_train_Y = df_train['Class']\n",
    "df_test_X = df_test[columns_no_class]\n",
    "df_test_Y = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_selection(algorithm,train_X):\n",
    "    \n",
    "    KNN_params = {'n_neighbors':range(1,51),'weights':['uniform','distance'],'algorithm':['ball_tree','kd_tree'],\n",
    "             'leaf_size':range(15,46),'n_jobs':[-1]}\n",
    "    \n",
    "    random_forest_params = {'n_estimators':range(1,51),'criterion':['gini','entropy'],\n",
    "                            'max_features':np.linspace(1./float(train_X.shape[1]),1.,50),'max_depth':range(1,51),\n",
    "                            'class_weight':[None],'n_jobs':[-1]}\n",
    "    \n",
    "    logistic_regression_params = {'tol':10.**(np.linspace(-6,-2,10)),'C':10.**np.linspace(-3,1,10),\n",
    "                                 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag'],'n_jobs':[-1]}\n",
    "    \n",
    "    param_dicts = {'knn':KNN_params,'random_forest':random_forest_params,'log_reg':logistic_regression_params}\n",
    "    \n",
    "    algorithm_dict = {'knn':KNeighborsClassifier(),'random_forest':RandomForestClassifier(),\n",
    "                      'log_reg':LogisticRegression()}\n",
    "    \n",
    "    return algorithm_dict[algorithm], param_dicts[algorithm]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(algorithm,train_X,train_Y):\n",
    "    \n",
    "    algo, params = model_selection(algorithm,train_X)\n",
    "\n",
    "    grid_search = RandomizedSearchCV(algo,param_distributions=params,n_iter=10,scoring='recall',cv=2,error_score=0.)\n",
    "\n",
    "    grid_search.fit(train_X,train_Y)\n",
    "    \n",
    "    print \"The results for %s:\" %algorithm\n",
    "    print \"The hyperparameters which give the highest recall:\"\n",
    "    print grid_search.best_params_\n",
    "    print\n",
    "    print \"The best score = %s\" %grid_search.best_score_\n",
    "    \n",
    "    np.save('%s_optimized_hyperparams.npy'%algorithm,grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validate(algorithm,train_X,train_Y,test_X,test_Y,optimized_params):\n",
    "    \n",
    "    algo = model_selection(algorithm,train_X)[0]\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        clf = algo.set_params(**optimized_params)\n",
    "        clf.fit(train_X,train_Y)\n",
    "        Y_pred = clf.predict(test_X)\n",
    "\n",
    "    except KeyError:\n",
    "        \n",
    "        print \"KeyError: algorithm selected has not been set up.\"\n",
    "        \n",
    "    print \"The precision using the best params = %s\" % precision_score(test_Y,Y_pred)\n",
    "    print\n",
    "    print \"The recall using the best params = %s\" % recall_score(test_Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_times_recall(estimator,x_test,y_test,c=1):\n",
    "    \n",
    "    Y_pred = estimator.predict(x_test)\n",
    "    \n",
    "    precision = precision_score(y_test,Y_pred)\n",
    "    recall = recall_score(y_test,Y_pred)\n",
    "    \n",
    "    return precision*recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for solver = newton-cg = 0.487804878049\n",
      "Amount of time to run = 0.987292051315\n",
      "\n",
      "Recall for solver = lbfgs = 0.487804878049\n",
      "Amount of time to run = 0.406782865524\n",
      "\n",
      "Recall for solver = liblinear = 0.487804878049\n",
      "Amount of time to run = 0.599906921387\n",
      "\n",
      "Recall for solver = sag = 0.479674796748\n",
      "Amount of time to run = 9.86556696892\n",
      "\n",
      "\n",
      "Optimized hyperparameters for random_forest loaded successfully:\n",
      "{'n_jobs': -1, 'n_estimators': 14, 'criterion': 'gini', 'max_features': 0.66938775510204085, 'max_depth': 7, 'class_weight': None}\n",
      "The precision using the best params = 0.906542056075\n",
      "\n",
      "The recall using the best params = 0.788617886179\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    pca = PCA(n_components=10)\n",
    "    pca_train_X = pca.fit_transform(df_train_X,df_train_Y)\n",
    "    pca_test_X = pca.transform(df_test_X)\n",
    "    \n",
    "# Choose algorithm from ['random_forest', 'knn', 'log_reg']\n",
    "    algorithm = 'log_reg'\n",
    "    \n",
    "    algo, params = model_selection(algorithm,pca_train_X)\n",
    "    \n",
    "    param = 'solver'\n",
    "    for i in params[param]:\n",
    "        \n",
    "        start = time()\n",
    "        \n",
    "        clf = algo.set_params(**{param:i})\n",
    "        clf.fit(pca_train_X,df_train_Y)\n",
    "        Y_pred = clf.predict(pca_test_X)\n",
    "        \n",
    "        print \"Recall for %s = %s = %s\" %(param,i,recall_score(df_test_Y,Y_pred))\n",
    "        print \"Amount of time to run = %s\" %(time()-start)\n",
    "        print\n",
    "        \n",
    "    \n",
    "    algorithm = 'random_forest'\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        optimized_params = np.load('%s_optimized_hyperparams.npy'%algorithm).item()\n",
    "        print\n",
    "        print \"Optimized hyperparameters for %s loaded successfully:\" %algorithm\n",
    "        print optimized_params\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print\n",
    "        print \"Need to obtain optimized hyperparameters for %s.\" %algorithm\n",
    "        optimize_hyperparameters(algorithm,pca_train_X,df_train_Y)\n",
    "        optimized_params = np.load('%s_optimized_hyperparams.npy'%algorithm).item()\n",
    "        \n",
    "    train_and_validate(algorithm,pca_train_X,df_train_Y,pca_test_X,df_test_Y,optimized_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with 1 trees is done.\n",
      "Run with 2 trees is done.\n",
      "Run with 3 trees is done.\n",
      "Run with 4 trees is done.\n",
      "Run with 5 trees is done.\n",
      "Run with 6 trees is done.\n",
      "Run with 7 trees is done.\n",
      "Run with 8 trees is done.\n",
      "Run with 9 trees is done.\n",
      "Run with 10 trees is done.\n",
      "Run with 11 trees is done.\n",
      "Run with 12 trees is done.\n",
      "Run with 13 trees is done.\n",
      "Run with 14 trees is done.\n",
      "Run with 15 trees is done.\n",
      "Run with 16 trees is done.\n",
      "Run with 17 trees is done.\n",
      "Run with 18 trees is done.\n",
      "Run with 19 trees is done.\n",
      "Run with 20 trees is done.\n",
      "Run with 21 trees is done.\n",
      "Run with 22 trees is done.\n",
      "Run with 23 trees is done.\n",
      "Run with 24 trees is done.\n",
      "Run with 25 trees is done.\n",
      "Run with 26 trees is done.\n",
      "Run with 27 trees is done.\n",
      "Run with 28 trees is done.\n",
      "Run with 29 trees is done.\n",
      "Run with 30 trees is done.\n"
     ]
    }
   ],
   "source": [
    "# Test the effect of n_estimators on precision and recall\n",
    "precision = []\n",
    "recall = []\n",
    "for i in range(1,31):\n",
    "    clf = RandomForestClassifier(n_estimators=i,criterion='entropy',max_features='auto',\n",
    "                                 class_weight={0:float(len(df_train_Y[df_train_Y==0]))/float(len(df_train_Y)),\n",
    "                                              1:float(len(df_train_Y[df_train_Y==1]))/float(len(df_train_Y))})\n",
    "    clf.fit(df_train_X,df_train_Y)\n",
    "    Y_pred = clf.predict(df_test_X)\n",
    "\n",
    "    P_R = precision_recall(df_test_Y,Y_pred,0)\n",
    "    \n",
    "    precision.append(P_R[0])\n",
    "    recall.append(P_R[1])\n",
    "    \n",
    "    print \"Run with %s trees is done.\" %i\n",
    "    \n",
    "#    print \"Number of trees = %s\" %i\n",
    "#    print \"The precision = %s\" %precision\n",
    "#    print \"The recall = %s\" %recall\n",
    "#    print \"The score with %s trees = %s\" %(i,clf.score(df_test_X,df_test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhA+RoC+EED7k/wHgxCiSZ6THpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eab3990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,31),precision[0],marker='o',color='k')\n",
    "plt.plot(range(1,31),recall[0],marker='o',color='r')\n",
    "\n",
    "plt.plot(range(1,31),precision[1],marker='|',color='k')\n",
    "plt.plot(range(1,31),recall[1],marker='|',color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr5RSIUSTvlJKhRBN+kopFUL+H+h8W3UzqoaSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111933690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,31),precision[0],marker='o',color='k')\n",
    "plt.plot(range(1,31),recall[0],marker='o',color='r')\n",
    "\n",
    "plt.plot(range(1,31),precision[1],marker='|',color='k')\n",
    "plt.plot(range(1,31),recall[1],marker='|',color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters which give the highest recall:\n",
      "{'n_jobs': -1, 'n_estimators': 26, 'criterion': 'gini', 'max_features': 0.30952380952380953, 'max_depth': 3, 'class_weight': {0: 0.0017274876524425926, 1: 0.9982725123475574}}\n",
      "\n",
      "The best estimator chosen:\n",
      "RandomForestClassifier(bootstrap=True,\n",
      "            class_weight={0: 0.0017274876524425926, 1: 0.9982725123475574},\n",
      "            criterion='gini', max_depth=3,\n",
      "            max_features=0.30952380952380953, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=26, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      "The best score chosen:\n",
      "0.864526977997\n"
     ]
    }
   ],
   "source": [
    "# Perform a randomized grid search for the hyperparameters which result in the highest recall,\n",
    "# using RandomForestClassifier\n",
    "random_forest_params = dict(zip(['n_estimators','criterion','max_features','max_depth','class_weight','n_jobs'],\n",
    "                               [range(1,51),['gini','entropy'],np.linspace(1./float(df_train_X.shape[1]),1.,50),\n",
    "                                range(1,51),[None,{0:float(len(df_train_Y[df_train_Y==0]))/float(len(df_train_Y)),\n",
    "                                              1:float(len(df_train_Y[df_train_Y==1]))/float(len(df_train_Y))},\n",
    "                                            {1:float(len(df_train_Y[df_train_Y==0]))/float(len(df_train_Y)),\n",
    "                                              0:float(len(df_train_Y[df_train_Y==1]))/float(len(df_train_Y))}],[-1]]))\n",
    "\n",
    "grid_search = RandomizedSearchCV(RandomForestClassifier(),param_distributions=random_forest_params,n_iter=100,\n",
    "                                scoring='recall',cv=2)\n",
    "\n",
    "grid_search.fit(df_train_X,df_train_Y)\n",
    "\n",
    "print \"The hyperparameters which give the highest recall:\"\n",
    "print grid_search.best_params_\n",
    "print\n",
    "print \"The best score chosen:\"\n",
    "print grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters which give the highest recall:\n",
      "{'n_jobs': -1, 'n_estimators': 35, 'criterion': 'gini', 'max_features': 0.54625850340136062, 'max_depth': 27, 'class_weight': None}\n",
      "\n",
      "The best score chosen:\n",
      "0.723893444109\n",
      "\n",
      "The precision using the best params = 0.95145631068\n",
      "\n",
      "The recall using the best params = 0.79674796748\n"
     ]
    }
   ],
   "source": [
    "# Perform a randomized grid search for the hyperparameters which result in the highest recall*precision,\n",
    "# using RandomForestClassifier\n",
    "random_forest_params = dict(zip(['n_estimators','criterion','max_features','max_depth','class_weight','n_jobs'],\n",
    "                               [range(1,51),['gini','entropy'],np.linspace(1./float(df_train_X.shape[1]),1.,50),\n",
    "                                range(1,51),[None],[-1]]))\n",
    "\n",
    "grid_search = RandomizedSearchCV(RandomForestClassifier(),param_distributions=random_forest_params,n_iter=100,\n",
    "                                scoring=precision_times_recall,cv=2)\n",
    "\n",
    "grid_search.fit(df_train_X,df_train_Y)\n",
    "\n",
    "print \"The hyperparameters which give the highest recall:\"\n",
    "print grid_search.best_params_\n",
    "print\n",
    "print \"The best score chosen:\"\n",
    "print grid_search.best_score_\n",
    "\n",
    "clf = RandomForestClassifier().set_params(**grid_search.best_params_)\n",
    "clf.fit(df_train_X,df_train_Y)\n",
    "Y_pred = clf.predict(df_test_X)\n",
    "\n",
    "print\n",
    "print \"The precision using the best params = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print\n",
    "print \"The recall using the best params = %s\" % recall_score(df_test_Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.95\n",
      "\n",
      "Recall = 0.772357723577\n",
      "IT took 752.680958986 seconds\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(df_train_X,df_train_Y)\n",
    "Y_pred = knn.predict(df_test_X)\n",
    "\n",
    "print \"Precision = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print\n",
    "print \"Recall = %s\" % recall_score(df_test_Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.958762886598\n",
      "\n",
      "Recall = 0.756097560976\n",
      "IT took 55.0104951859 seconds\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "\n",
    "knn_train_X = pca.fit_transform(df_train_X,df_train_Y)\n",
    "\n",
    "knn_test_X = pca.transform(df_test_X)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(knn_train_X,df_train_Y)\n",
    "Y_pred = knn.predict(knn_test_X)\n",
    "\n",
    "print \"Precision = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print\n",
    "print \"Recall = %s\" % recall_score(df_test_Y,Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KNN_params = {'n_neighbors':range(1,51),'weights':['uniform','distance'],'algorithm':['ball_tree','kd_tree'],\n",
    "             'leaf_size':range(15,46),'n_jobs':[-1]}\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "knn_train_X = pca.fit_transform(df_train_X,df_train_Y)\n",
    "knn_test_X = pca.transform(df_test_X)\n",
    "\n",
    "grid_search = RandomizedSearchCV(KNeighborsClassifier(),param_distributions=KNN_params,n_iter=100,\n",
    "                                 scoring=precision_times_recall,cv=2)\n",
    "\n",
    "grid_search.fit(knn_train_X,df_train_Y)\n",
    "\n",
    "print \"The hyperparameters which give the highest recall:\"\n",
    "print grid_search.best_params_\n",
    "print\n",
    "print \"The best score = %s\" %grid_search.best_score_\n",
    "\n",
    "clf = KNeighborsClassifier().set_params(**grid_search.best_params_)\n",
    "clf.fit(knn_train_X,df_train_Y)\n",
    "Y_pred = clf.predict(knn_test_X)\n",
    "\n",
    "print\n",
    "print \"The precision using the best params = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print\n",
    "print \"The recall using the best params = %s\" % recall_score(df_test_Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Need to obtain optimized hyperparameters for log_reg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yevgenikissin/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.947916666667\n",
      "\n",
      "Recall = 0.739837398374\n",
      "IT took 31.4692268372 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn_train_X = df_train_X[df_train_X.columns[1:12]].copy()\n",
    "knn_test_X = df_test_X[df_train_X.columns[1:12]].copy()\n",
    "\n",
    "start = time()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(knn_train_X,df_train_Y)\n",
    "Y_pred = knn.predict(knn_test_X)\n",
    "\n",
    "print \"Precision = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print\n",
    "print \"Recall = %s\" % recall_score(df_test_Y,Y_pred)\n",
    "\n",
    "print \"IT took %s seconds\" %(time()-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-47b46c96d211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprecision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-f4432ae17121>\u001b[0m in \u001b[0;36mprecision_recall\u001b[0;34m(y_test, y_pred, c)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_pred_is_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Precision = %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_is_c\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0my_pred_is_c\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yevgenikissin/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    730\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10,criterion='entropy',max_features='auto')\n",
    "clf.fit(df_train_X,df_train_Y)\n",
    "Y_pred = clf.predict(df_test_X)\n",
    "\n",
    "precision_recall(df_test_Y,Y_pred,1)\n",
    "\n",
    "feature_importance = zip(df_train.columns,clf.feature_importances_)\n",
    "feature_importance = sorted(feature_importance,key=lambda x: x[1], reverse=True)\n",
    "feature_names = zip(*feature_importance)[0]\n",
    "print \"The 3 dominant features are = %s, %s, and %s\" %(feature_names[0],feature_names[1],feature_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision according to my calculation = 0.948453608247\n",
      "The recall according to my calculation = 0.747967479675\n",
      "\n",
      "The precision according to sklearn calculation = 0.948453608247\n",
      "The recall according to sklearn calculation = 0.747967479675\n",
      "The precision according to my calculation = 0.949494949495\n",
      "The recall according to my calculation = 0.764227642276\n",
      "\n",
      "The precision according to sklearn calculation = 0.949494949495\n",
      "The recall according to sklearn calculation = 0.764227642276\n",
      "The precision according to my calculation = 0.967741935484\n",
      "The recall according to my calculation = 0.731707317073\n",
      "\n",
      "The precision according to sklearn calculation = 0.967741935484\n",
      "The recall according to sklearn calculation = 0.731707317073\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5,criterion='entropy',max_features='auto',\n",
    "                                 class_weight={0:float(len(df_train_Y[df_train_Y==0]))/float(len(df_train_Y)),\n",
    "                                              1:float(len(df_train_Y[df_train_Y==1]))/float(len(df_train_Y))})\n",
    "clf.fit(df_train_X,df_train_Y)\n",
    "Y_pred = clf.predict(df_test_X)\n",
    "\n",
    "P_R = precision_recall(df_test_Y,Y_pred,1)\n",
    "\n",
    "print \"The precision according to my calculation = %s\" %P_R[0]\n",
    "print \"The recall according to my calculation = %s\" %P_R[1]\n",
    "print\n",
    "print \"The precision according to sklearn calculation = %s\" % precision_score(df_test_Y,Y_pred)\n",
    "print \"The recall according to sklearn calculation = %s\" %recall_score(df_test_Y,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999508440774\n",
      "0.998398921379\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "The precision = 0.0637645616186\n",
      "The recall = 0.845528455285\n",
      "Naive Bayes:\n",
      "The precision = 0.0637645616186\n",
      "The recall = 0.845528455285\n",
      "The number of predicted fraud cases = 1631\n",
      "The number of actual fraud cases = 123\n"
     ]
    }
   ],
   "source": [
    "clf_bayes = GaussianNB()\n",
    "clf_bayes.fit(df_train_X,df_train_Y)\n",
    "Y_pred = clf_bayes.predict(df_test_X)\n",
    "\n",
    "P_R = precision_recall(df_test_Y,Y_pred,1)\n",
    "\n",
    "print \"Naive Bayes:\"\n",
    "print \"The precision = %s\" % P_R[0]\n",
    "print \"The recall = %s\" % P_R[1]\n",
    "\n",
    "prior = [float(len(df_train_Y[df_train_Y==0]))/float(len(df_train_Y)),\n",
    "         float(len(df_train_Y[df_train_Y==1]))/float(len(df_train_Y))]\n",
    "\n",
    "clf_bayes = GaussianNB(prior)\n",
    "clf_bayes.fit(df_train_X,df_train_Y)\n",
    "Y_pred = clf_bayes.predict(df_test_X)\n",
    "\n",
    "P_R = precision_recall(df_test_Y,Y_pred,1)\n",
    "\n",
    "print \"Naive Bayes:\"\n",
    "print \"The precision = %s\" % P_R[0]\n",
    "print \"The recall = %s\" % P_R[1]\n",
    "\n",
    "print \"The number of predicted fraud cases = %s\" % len(Y_pred[Y_pred==1])\n",
    "print \"The number of actual fraud cases = %s\" % len(df_test_Y[df_test_Y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('V17', 0.16995329574024545), ('V11', 0.1270129304294387), ('V14', 0.12409809809914432), ('V10', 0.12046467782453725), ('V12', 0.084706073904392526), ('V4', 0.074360756466227335), ('V7', 0.04078441260086433), ('V3', 0.025478560126986859), ('V2', 0.023805335802521557), ('V16', 0.017455024156609988), ('V1', 0.017234412866801448), ('V18', 0.015157055972968566), ('V26', 0.011984614118157993), ('V19', 0.011610333006659816), ('V6', 0.011155835620898662), ('V8', 0.011100711602187506), ('Amount', 0.011009727909587938), ('V20', 0.010922177040988456), ('V27', 0.010245667175239415), ('V9', 0.0097621538300886705), ('V28', 0.0094958023285274338), ('V15', 0.0090106492053403306), ('V21', 0.0088768340149149531), ('Time', 0.0078011102741095562), ('V22', 0.0077289083829639362), ('V5', 0.0073153029627284882), ('V24', 0.0060454794371867559), ('V23', 0.0052670661607764294), ('V13', 0.005194553586498632), ('V25', 0.0049624393524066758)]\n",
      "\n",
      "\n",
      "[('V17', 0.16995329574024545), ('V11', 0.1270129304294387), ('V14', 0.12409809809914432), ('V10', 0.12046467782453725), ('V12', 0.084706073904392526), ('V4', 0.074360756466227335), ('V7', 0.04078441260086433), ('V3', 0.025478560126986859), ('V2', 0.023805335802521557), ('V16', 0.017455024156609988), ('V1', 0.017234412866801448), ('V18', 0.015157055972968566), ('V26', 0.011984614118157993), ('V19', 0.011610333006659816), ('V6', 0.011155835620898662), ('V8', 0.011100711602187506), ('Amount', 0.011009727909587938), ('V20', 0.010922177040988456), ('V27', 0.010245667175239415), ('V9', 0.0097621538300886705), ('V28', 0.0094958023285274338), ('V15', 0.0090106492053403306), ('V21', 0.0088768340149149531), ('Time', 0.0078011102741095562), ('V22', 0.0077289083829639362), ('V5', 0.0073153029627284882), ('V24', 0.0060454794371867559), ('V23', 0.0052670661607764294), ('V13', 0.005194553586498632), ('V25', 0.0049624393524066758)]\n",
      "('V17', 'V11', 'V14', 'V10', 'V12', 'V4', 'V7', 'V3', 'V2', 'V16', 'V1', 'V18', 'V26', 'V19', 'V6', 'V8', 'Amount', 'V20', 'V27', 'V9', 'V28', 'V15', 'V21', 'Time', 'V22', 'V5', 'V24', 'V23', 'V13', 'V25')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def P_times_R_slow_version(estimator,x_test,y_test,c=1):\n",
    "    \n",
    "    Y_pred = estimator.predict(x_test)\n",
    "    \n",
    "    true_pos = 0.\n",
    "    false_pos = 0.\n",
    "    true_neg = 0.\n",
    "    false_neg = 0.\n",
    "    \n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    for i in range(y_test.shape[0]):\n",
    "        \n",
    "        if (y_test[i]==c and Y_pred[i]==c):\n",
    "            true_pos += 1.\n",
    "        elif (y_test[i]==c and Y_pred[i]!=c):\n",
    "            false_neg += 1.\n",
    "        elif (y_test[i]!=c and Y_pred[i]==c):\n",
    "            false_pos += 1.\n",
    "        elif (y_test[i]!=c and Y_pred[i]!=c):\n",
    "            true_neg += 1.\n",
    "\n",
    "\n",
    "    #print \"Total number of samples = %s\" %y_test.shape\n",
    "    #print \"Total number of true_pos = %s\" %true_pos\n",
    "    #print \"Total number of false_pos = %s\" %false_pos\n",
    "    #print \"Total number of true_neg = %s\" %true_neg\n",
    "    #print \"Total number of false_neg = %s\" %false_neg\n",
    "\n",
    "    \n",
    "    #print \"Precision = %s\" % (true_pos/(false_pos+true_pos))\n",
    "    #print \"Recall = %s\" % (true_pos/(false_neg+true_pos))\n",
    "    \n",
    "    return true_pos**2./((false_neg+true_pos)*(false_pos+true_pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
